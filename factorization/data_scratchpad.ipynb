{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2146)\n",
      "tensor(0.2272)\n",
      "tensor(0.2811)\n",
      "tensor(0.1891)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2833)\n",
      "tensor(0.2067)\n",
      "tensor(0.2339)\n",
      "tensor(0.2494)\n",
      "tensor(0.2236)\n",
      "tensor(0.1880)\n",
      "tensor(0.2136)\n",
      "tensor(0.2392)\n",
      "tensor(0.1730)\n",
      "tensor(0.1848)\n",
      "tensor(0.3161)\n",
      "tensor(0.2534)\n",
      "tensor(0.1773)\n",
      "tensor(0.2346)\n",
      "tensor(0.2218)\n",
      "tensor(0.2208)\n",
      "tensor(0.1536)\n",
      "tensor(0.1981)\n",
      "tensor(0.1817)\n",
      "tensor(0.2015)\n",
      "tensor(0.1841)\n",
      "tensor(0.1945)\n",
      "tensor(0.1786)\n",
      "tensor(0.2205)\n",
      "tensor(0.2161)\n",
      "tensor(0.2053)\n",
      "tensor(0.2318)\n",
      "tensor(0.1715)\n",
      "tensor(0.2262)\n",
      "tensor(0.2172)\n",
      "tensor(0.1974)\n",
      "tensor(0.1677)\n",
      "tensor(0.1969)\n",
      "tensor(0.1728)\n",
      "tensor(0.1558)\n",
      "tensor(0.2152)\n",
      "tensor(0.2279)\n",
      "tensor(0.1759)\n",
      "tensor(0.1630)\n",
      "tensor(0.2206)\n",
      "tensor(0.1742)\n",
      "tensor(0.2363)\n",
      "tensor(0.2471)\n",
      "tensor(0.2165)\n",
      "tensor(0.1672)\n",
      "tensor(0.3536)\n",
      "tensor(0.1785)\n",
      "tensor(0.1901)\n",
      "tensor(0.2034)\n",
      "tensor(0.2586)\n",
      "tensor(0.1960)\n",
      "tensor(0.1993)\n",
      "tensor(0.2109)\n",
      "tensor(0.2006)\n",
      "tensor(0.1588)\n",
      "tensor(0.2650)\n",
      "tensor(0.2455)\n",
      "tensor(0.2446)\n",
      "tensor(0.1970)\n",
      "tensor(0.2884)\n",
      "tensor(0.2127)\n",
      "tensor(0.1673)\n",
      "tensor(0.2186)\n",
      "tensor(0.1936)\n",
      "tensor(0.2053)\n",
      "tensor(0.2672)\n",
      "tensor(0.1459)\n",
      "tensor(0.2102)\n",
      "tensor(0.2386)\n",
      "tensor(0.2025)\n",
      "tensor(0.1706)\n",
      "tensor(0.2225)\n",
      "tensor(0.1930)\n",
      "tensor(0.2021)\n",
      "tensor(0.1713)\n",
      "tensor(0.3090)\n",
      "tensor(0.2810)\n",
      "tensor(0.2268)\n",
      "tensor(0.3480)\n",
      "tensor(0.1695)\n",
      "tensor(0.2413)\n",
      "tensor(0.2185)\n",
      "tensor(0.1951)\n",
      "tensor(0.2873)\n",
      "tensor(0.2443)\n",
      "tensor(0.2910)\n",
      "tensor(0.2559)\n",
      "tensor(0.1982)\n",
      "tensor(0.2247)\n",
      "tensor(0.1853)\n",
      "tensor(0.2071)\n",
      "tensor(0.1997)\n",
      "tensor(0.2451)\n",
      "tensor(0.2472)\n",
      "tensor(0.2393)\n",
      "tensor(0.2522)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nb_classes = int(2e4)\n",
    "alpha = 1e-3\n",
    "for i in range(100):\n",
    "    tmp = Dirichlet(concentration = torch.tensor([alpha, ] * nb_classes)).sample((20,)).max()\n",
    "    if np.abs(tmp.max().item() - 1) > .1:\n",
    "        print(tmp.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_input = 2**10\n",
    "factor_emb_dim = 10\n",
    "input_factors = [3, 4, 2, 4, 1]\n",
    "output_factors = [2, 3, 1, 1, 1]\n",
    "alphas = [1e-3, 1e-3, 1e-3, 1e-3, 1e-3]\n",
    "alphas = [100., ] * 5\n",
    "\n",
    "all_emb = torch.randn((nb_input, factor_emb_dim))\n",
    "\n",
    "\n",
    "p_y_x = torch.ones((nb_input, *output_factors))\n",
    "view = [nb_input] + [1, ] * len(input_factors)\n",
    "\n",
    "for i, (alpha, input_factor, output_factor) in enumerate(zip(alphas, input_factors, output_factors)):\n",
    "    directions = torch.randn((factor_emb_dim, input_factor))\n",
    "    sign = (all_emb @ directions).sign()\n",
    "    value = (torch.tensor([2 ** i for i in range(input_factor)]) * sign).sum(axis=1)\n",
    "\n",
    "    p_yi = Dirichlet(concentration = torch.tensor([alpha, ] * output_factor)).sample((2 ** input_factor, ))\n",
    "    p_yis_x = p_yi[value.long()]\n",
    "\n",
    "    view[i+1] = output_factor\n",
    "    p_y_x *= p_yis_x.view(view)\n",
    "    view[i+1] = 1\n",
    "\n",
    "p_y_x = p_y_x.view(nb_input, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 2, 3, 1, 1, 1]), torch.Size([1024, 1]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_x.shape, p_yis_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2 ** i for i in range(size_factor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = [(torch.tensor([2 ** i for i in range(U.shape[1])]) * (torch.sign(x @ U) + 1) / 2).sum(axis=1) for U in Us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2**3)[zx[0].to(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_yi in p_yi_list[1:]:\n",
    "    p_y = p_y[..., np.newaxis] * p_yi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Probability Distribution: [0.03 0.12 0.07 0.28 0.03 0.12 0.07 0.28]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def joint_probability_numpy(p_yi_list):\n",
    "    \"\"\"\n",
    "    Computes the joint probability distribution p(y) as the product of p(y_i).\n",
    "    \n",
    "    Args:\n",
    "        p_yi_list (list of np.ndarray): List of probability vectors for each discrete factor y_i.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Joint probability distribution vector p(y).\n",
    "    \"\"\"\n",
    "    # Ensure the list is not empty\n",
    "    if not p_yi_list:\n",
    "        raise ValueError(\"The list of probability vectors cannot be empty.\")\n",
    "    \n",
    "    # Start with the first probability vector\n",
    "    p_y = p_yi_list[0]\n",
    "    \n",
    "    # Multiply the probability vectors element-wise\n",
    "    for p_yi in p_yi_list[1:]:\n",
    "        p_y = p_y[..., np.newaxis] * p_yi  # Broadcasting for multiplication\n",
    "    \n",
    "    # Flatten the result to get a 1D joint probability distribution\n",
    "    return p_y.flatten()\n",
    "\n",
    "# Example usage\n",
    "p_y1 = np.array([0.5, 0.5])  # p(y1)\n",
    "p_y2 = np.array([0.3, 0.7])  # p(y2)\n",
    "p_y3 = np.array([0.2, 0.8])  # p(y3)\n",
    "\n",
    "joint_p = joint_probability_numpy([p_y1, p_y2, p_y3])\n",
    "print(\"Joint Probability Distribution:\", joint_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
